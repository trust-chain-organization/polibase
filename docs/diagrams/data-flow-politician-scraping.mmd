```mermaid
sequenceDiagram
    autonumber
    actor User
    participant CLI as CLI Command
    participant UseCase as ScrapePoliticiansUseCase
    participant Scraper as IWebScraperService
    participant LLM as ILLMService
    participant DomainSvc as PoliticianDomainService
    participant ExtractedRepo as IExtractedPoliticianRepository
    participant PoliticianRepo as IPoliticianRepository
    participant PartyRepo as IPoliticalPartyRepository
    participant DB as Database

    User->>CLI: polibase scrape-politicians --party-id 5
    activate CLI

    CLI->>UseCase: execute(party_id=5)
    activate UseCase

    %% Fetch party information
    UseCase->>PartyRepo: get_party(5)
    activate PartyRepo
    PartyRepo->>DB: SELECT * FROM political_parties WHERE id=5
    DB-->>PartyRepo: party data (with members_list_url)
    PartyRepo-->>UseCase: PoliticalParty entity
    deactivate PartyRepo

    alt members_list_url is None
        UseCase-->>CLI: Error: No members list URL configured
        CLI-->>User: ✗ Please configure members_list_url first
    end

    %% Scrape party website
    UseCase->>Scraper: scrape_page(members_list_url)
    activate Scraper
    Note over Scraper: Uses Playwright<br/>Handles JavaScript
    Scraper-->>UseCase: HTML content
    deactivate Scraper

    %% Extract structured data with LLM
    UseCase->>LLM: extract_politicians(html_content)
    activate LLM
    Note over LLM: Gemini API extracts:<br/>- Name<br/>- District<br/>- Position<br/>- Profile URL
    LLM-->>UseCase: politicians_data (JSON)
    deactivate LLM

    loop For each politician data
        UseCase->>DomainSvc: validate_politician_data(data)
        activate DomainSvc
        DomainSvc->>DomainSvc: check required fields
        DomainSvc->>DomainSvc: normalize name
        DomainSvc-->>UseCase: validated data
        deactivate DomainSvc

        %% Check for duplicates
        UseCase->>PoliticianRepo: find_by_name_and_party(name, party_id)
        activate PoliticianRepo
        PoliticianRepo->>DB: SELECT * FROM politicians WHERE name=? AND party_id=?
        DB-->>PoliticianRepo: existing politician or None
        PoliticianRepo-->>UseCase: Optional[Politician]
        deactivate PoliticianRepo

        alt Politician exists
            Note over UseCase: Skip duplicate<br/>Update if needed
            UseCase->>PoliticianRepo: update(politician_id, data)
            activate PoliticianRepo
            PoliticianRepo->>DB: UPDATE politicians SET...
            DB-->>PoliticianRepo: updated
            PoliticianRepo-->>UseCase: success
            deactivate PoliticianRepo
        else New politician
            %% Save to staging table for review
            UseCase->>DomainSvc: create_extracted_politician(data, party_id)
            activate DomainSvc
            DomainSvc-->>UseCase: ExtractedPolitician entity
            deactivate DomainSvc

            UseCase->>ExtractedRepo: save(extracted_politician)
            activate ExtractedRepo
            ExtractedRepo->>DB: INSERT INTO extracted_politicians
            DB-->>ExtractedRepo: extracted_politician_id
            ExtractedRepo-->>UseCase: saved ExtractedPolitician
            deactivate ExtractedRepo
        end
    end

    UseCase-->>CLI: ScrapingResult(extracted=25, updated=5, duplicates=3)
    deactivate UseCase

    CLI-->>User: ✓ Extracted 25 new politicians, updated 5, skipped 3 duplicates
    deactivate CLI

    Note over User,DB: --- Manual Review Process ---

    actor Admin
    Admin->>User: Review extracted politicians in Streamlit UI
    Admin->>ExtractedRepo: approve(extracted_politician_id)
    activate ExtractedRepo

    ExtractedRepo->>ExtractedRepo: validate status=pending
    ExtractedRepo->>DB: UPDATE extracted_politicians SET status='approved'
    DB-->>ExtractedRepo: updated

    ExtractedRepo->>PoliticianRepo: convert_to_politician(extracted_politician)
    activate PoliticianRepo
    PoliticianRepo->>DB: INSERT INTO politicians
    DB-->>PoliticianRepo: politician_id
    PoliticianRepo-->>ExtractedRepo: Politician entity
    deactivate PoliticianRepo

    ExtractedRepo->>DB: UPDATE extracted_politicians SET status='converted', politician_id=?
    DB-->>ExtractedRepo: updated

    ExtractedRepo-->>Admin: ✓ Converted to Politician
    deactivate ExtractedRepo
```

## Politician Scraping Data Flow

This sequence diagram shows the complete workflow of scraping politician data from party websites, including the staged review process.

### Three-Stage Process

#### Stage 1: Scraping & Extraction
1. Fetch party's member list URL
2. Scrape webpage with Playwright
3. Extract structured data using LLM
4. Validate and normalize data

#### Stage 2: Duplicate Check & Staging
1. Check for existing politicians (name + party)
2. Update existing records if found
3. Save new politicians to staging table (`extracted_politicians`)
4. Status = `pending` for manual review

#### Stage 3: Review & Conversion (Manual)
1. Admin reviews in Streamlit UI
2. Approves or rejects extracted data
3. Approved data converts to `politicians` table
4. Status updates to `converted`

### Data Transformations

```
Party Website → HTML → LLM JSON → ExtractedPolitician → (Review) → Politician
```

### Why Staging Table?

1. **Quality Control**: Human review before adding to master data
2. **Error Detection**: Catch LLM extraction mistakes
3. **Duplicate Prevention**: Verify no duplicates exist
4. **Audit Trail**: Track what was extracted and when

### Status Flow

```
pending → approved → converted
   ↓
rejected
```

### Duplicate Detection

Duplicates are detected by:
- Exact name match + same party
- Similar name + same district (requires review)
- Profile URL match (if available)
