# Use absolute import from the 'src' package when running as a module
import src.config.config as config
from src.utils.text_extractor import extract_text_from_pdf
from src.database.conversation_repository import ConversationRepository
from langchain_google_genai import ChatGoogleGenerativeAI
# Absolute import for MinutesProcessAgent
from src.minutes_divide_processor.minutes_process_agent import MinutesProcessAgent
from typing import List
import os

# config.pyã‚’å‘¼ã³å‡ºã—ã¦ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
config.set_env()

# PDF ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
try:
    with open('data/minutes.pdf', 'rb') as f:
        file_content = f.read()
except FileNotFoundError:
    print("Source file not found: data/minutes.pdf")
    exit()
extracted_text = extract_text_from_pdf(file_content)

def save_to_database(speaker_and_speech_content_list: List) -> List[int]:
    """
    SpeakerAndSpeechContentã®ãƒªã‚¹ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®Conversationsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ã™ã‚‹
    
    Args:
        speaker_and_speech_content_list: ä¿å­˜ã™ã‚‹ç™ºè¨€ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        
    Returns:
        List[int]: ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ã®IDãƒªã‚¹ãƒˆ
    """
    conversation_repo = ConversationRepository()
    try:
        saved_ids = conversation_repo.save_speaker_and_speech_content_list(speaker_and_speech_content_list)
        print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†: {len(saved_ids)}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        return saved_ids
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        raise

def display_database_status():
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çŠ¶æ…‹ã‚’è¡¨ç¤ºã™ã‚‹
    """
    try:
        conversation_repo = ConversationRepository()
        count = conversation_repo.get_conversations_count()
        stats = conversation_repo.get_speaker_linking_stats()
        
        print(f"ğŸ“Š ç¾åœ¨ã®Conversationsãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {count}ä»¶")
        print(f"   - Speakerç´ä»˜ã‘ã‚ã‚Š: {stats['linked_conversations']}ä»¶")
        print(f"   - Speakerç´ä»˜ã‘ãªã—: {stats['unlinked_conversations']}ä»¶")
        
        if count > 0:
            print("\nğŸ“‹ æœ€æ–°ã®5ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰:")
            conversations = conversation_repo.get_all_conversations()[:5]
            for conv in conversations:
                linked_info = f"â†’ {conv['linked_speaker_name']}" if conv['linked_speaker_name'] else "ï¼ˆç´ä»˜ã‘ãªã—ï¼‰"
                print(f"  ID: {conv['id']}, ç™ºè¨€è€…: {conv['speaker_name']} {linked_info}")
                print(f"      ç™ºè¨€: {conv['comment'][:50]}...")
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

def main():
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
    print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
    from src.config.database import test_connection
    if not test_connection():
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚docker compose ã§PostgreSQLãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None
    
    print("ğŸ“Š å‡¦ç†å‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹:")
    display_database_status()
    
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
    agent = MinutesProcessAgent(llm=llm)
    speaker_and_speech_content_list = agent.run(original_minutes=extracted_text)
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ (CSVãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã«å¤‰æ›´)
    saved_ids = save_to_database(speaker_and_speech_content_list)
    print(f"ç™ºè¨€ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸã€‚{len(saved_ids)}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    
    print("\nğŸ“Š å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹:")
    display_database_status()
    
    return speaker_and_speech_content_list

if __name__ == "__main__":
    speaker_and_speech_content_list = main()
    print("--------çµæœå‡ºåŠ›--------")
    print(speaker_and_speech_content_list)
    print('å…¨éƒ¨çµ‚ã‚ã£ãŸã‚ˆ')
