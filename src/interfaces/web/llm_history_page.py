"""LLMå‡¦ç†å±¥æ­´ç…§ä¼šãƒšãƒ¼ã‚¸"""

import csv
import io
from datetime import datetime, timedelta
from typing import Any

import pandas as pd

import streamlit as st
from src.config.database import get_db_session_context
from src.domain.entities.llm_processing_history import (
    LLMProcessingHistory,
    ProcessingStatus,
    ProcessingType,
)
from src.infrastructure.persistence.llm_processing_history_repository_impl import (
    LLMProcessingHistoryRepositoryImpl,
)
from src.infrastructure.persistence.repository_adapter import RepositoryAdapter


def render_llm_history_page():
    """LLMå‡¦ç†å±¥æ­´ç…§ä¼šãƒšãƒ¼ã‚¸ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    st.header("ğŸ¤– LLMå‡¦ç†å±¥æ­´")
    st.markdown("LLM APIã®å‡¦ç†å±¥æ­´ã‚’ç…§ä¼šãƒ»æ¤œç´¢ã§ãã¾ã™")

    # ã‚¿ãƒ–ä½œæˆ
    tab1, tab2 = st.tabs(["å±¥æ­´ä¸€è¦§", "çµ±è¨ˆæƒ…å ±"])

    with tab1:
        render_history_list()

    with tab2:
        render_statistics()


def render_history_list():
    """å±¥æ­´ä¸€è¦§ã‚’è¡¨ç¤º"""
    st.subheader("å‡¦ç†å±¥æ­´ä¸€è¦§")

    # æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    with st.expander("ğŸ” æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", expanded=True):
        col1, col2, col3 = st.columns(3)

        with col1:
            # å‡¦ç†ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            processing_types = ["ã™ã¹ã¦"] + [pt.value for pt in ProcessingType]
            selected_type = st.selectbox(
                "å‡¦ç†ã‚¿ã‚¤ãƒ—",
                processing_types,
                key="filter_processing_type",
            )

        with col2:
            # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            model_names = ["ã™ã¹ã¦", "gemini-2.0-flash", "gemini-1.5-flash", "ãã®ä»–"]
            selected_model = st.selectbox(
                "ãƒ¢ãƒ‡ãƒ«",
                model_names,
                key="filter_model",
            )

        with col3:
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            statuses = ["ã™ã¹ã¦"] + [s.value for s in ProcessingStatus]
            selected_status = st.selectbox(
                "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
                statuses,
                key="filter_status",
            )

        # æ—¥ä»˜ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        col4, col5 = st.columns(2)
        with col4:
            default_start_date = datetime.now() - timedelta(days=30)
            start_date = st.date_input(
                "é–‹å§‹æ—¥",
                value=default_start_date,
                key="filter_start_date",
            )

        with col5:
            end_date = st.date_input(
                "çµ‚äº†æ—¥",
                value=datetime.now(),
                key="filter_end_date",
            )

    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
    items_per_page = st.selectbox(
        "è¡¨ç¤ºä»¶æ•°",
        [10, 25, 50, 100],
        index=1,
        key="items_per_page",
    )

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’æ§‹ç¯‰
    processing_type = (
        None if selected_type == "ã™ã¹ã¦" else ProcessingType(selected_type)
    )
    model_name = None if selected_model == "ã™ã¹ã¦" else selected_model
    status = None if selected_status == "ã™ã¹ã¦" else ProcessingStatus(selected_status)

    # æ¤œç´¢å®Ÿè¡Œ
    if start_date and end_date:
        start_datetime = datetime.combine(start_date, datetime.min.time())
        end_datetime = datetime.combine(end_date, datetime.max.time())
    else:
        start_datetime = None
        end_datetime = None

    # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ç•ªå·ã‚’å–å¾—
    if "current_page" not in st.session_state:
        st.session_state.current_page = 0

    offset = st.session_state.current_page * items_per_page

    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    with get_db_session_context():
        repo = RepositoryAdapter(LLMProcessingHistoryRepositoryImpl)

        # å±¥æ­´ã‚’æ¤œç´¢
        histories = repo.search(
            processing_type=processing_type,
            model_name=model_name,
            status=status,
            start_date=start_datetime,
            end_date=end_datetime,
            limit=items_per_page,
            offset=offset,
        )

        # ç·ä»¶æ•°ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
        total_count = repo.count_by_status(
            status=status if status else ProcessingStatus.COMPLETED,
            processing_type=processing_type,
        )

    # çµæœè¡¨ç¤º
    if histories:
        # CSV ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒœã‚¿ãƒ³
        csv_data = generate_csv_data(histories)
        st.download_button(
            label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name=f"llm_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
        )

        # å±¥æ­´ã‚’è¡¨ç¤º
        for history in histories:
            render_history_item(history)

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
        total_pages = (total_count + items_per_page - 1) // items_per_page
        render_pagination(total_pages)

    else:
        st.info("æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def render_history_item(history: LLMProcessingHistory) -> None:
    """å€‹åˆ¥ã®å±¥æ­´é …ç›®ã‚’è¡¨ç¤º"""
    with st.container():
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        col1, col2, col3, col4 = st.columns([3, 2, 2, 1])

        with col1:
            st.markdown(f"**{history.processing_type.value}**")
            st.caption(f"ID: {history.id}")

        with col2:
            st.markdown(f"ğŸ“Š {history.model_name}")
            if history.model_version:
                st.caption(f"Ver: {history.model_version}")

        with col3:
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ãŸãƒãƒƒã‚¸è¡¨ç¤º
            status_emoji = {
                ProcessingStatus.COMPLETED: "âœ…",
                ProcessingStatus.FAILED: "âŒ",
                ProcessingStatus.IN_PROGRESS: "â³",
                ProcessingStatus.PENDING: "â¸ï¸",
            }
            emoji = status_emoji.get(history.status, "â“")
            st.markdown(f"{emoji} {history.status.value}")

            # å‡¦ç†æ™‚é–“ã‚’è¡¨ç¤º
            if history.processing_duration_seconds:
                st.caption(f"å‡¦ç†æ™‚é–“: {history.processing_duration_seconds:.2f}ç§’")

        with col4:
            if st.button("è©³ç´°", key=f"detail_{history.id}"):
                st.session_state[
                    f"show_detail_{history.id}"
                ] = not st.session_state.get(f"show_detail_{history.id}", False)

        # è©³ç´°è¡¨ç¤º
        if st.session_state.get(f"show_detail_{history.id}", False):
            render_history_detail(history)

        st.divider()


def render_history_detail(history: LLMProcessingHistory) -> None:
    """å±¥æ­´ã®è©³ç´°ã‚’è¡¨ç¤º"""
    with st.expander("è©³ç´°æƒ…å ±", expanded=True):
        # åŸºæœ¬æƒ…å ±
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**åŸºæœ¬æƒ…å ±**")
            ref_text = (
                f"å…¥åŠ›å‚ç…§: {history.input_reference_type} "
                f"#{history.input_reference_id}"
            )
            st.text(ref_text)
            if history.started_at:
                st.text(f"é–‹å§‹: {history.started_at.strftime('%Y-%m-%d %H:%M:%S')}")
            if history.completed_at:
                st.text(f"å®Œäº†: {history.completed_at.strftime('%Y-%m-%d %H:%M:%S')}")

        with col2:
            st.markdown("**ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**")
            if history.processing_metadata:
                for key, value in history.processing_metadata.items():
                    st.text(f"{key}: {value}")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæƒ…å ±
        st.markdown("**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**")
        st.code(history.prompt_template, language="text")

        if history.prompt_variables:
            st.markdown("**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ•°**")
            st.json(history.prompt_variables)

        # çµæœã¾ãŸã¯ã‚¨ãƒ©ãƒ¼
        if history.status == ProcessingStatus.COMPLETED and history.result:
            st.markdown("**å‡¦ç†çµæœ**")
            st.json(history.result)
        elif history.status == ProcessingStatus.FAILED and history.error_message:
            st.markdown("**ã‚¨ãƒ©ãƒ¼å†…å®¹**")
            st.error(history.error_message)


def render_pagination(total_pages: int):
    """ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º"""
    if total_pages <= 1:
        return

    col1, col2, col3 = st.columns([2, 3, 2])

    with col1:
        if st.button("â—€ å‰ã¸", disabled=st.session_state.current_page == 0):
            st.session_state.current_page -= 1
            st.rerun()

    with col2:
        page_text = (
            f"<div style='text-align: center'>"
            f"ãƒšãƒ¼ã‚¸ {st.session_state.current_page + 1} / {total_pages}"
            f"</div>"
        )
        st.markdown(page_text, unsafe_allow_html=True)

    with col3:
        if st.button(
            "æ¬¡ã¸ â–¶", disabled=st.session_state.current_page >= total_pages - 1
        ):
            st.session_state.current_page += 1
            st.rerun()


def render_statistics():
    """çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
    st.subheader("çµ±è¨ˆæƒ…å ±")

    # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    with get_db_session_context():
        repo = RepositoryAdapter(LLMProcessingHistoryRepositoryImpl)

        # å„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ä»¶æ•°ã‚’å–å¾—
        completed_count = repo.count_by_status(ProcessingStatus.COMPLETED)
        failed_count = repo.count_by_status(ProcessingStatus.FAILED)
        in_progress_count = repo.count_by_status(ProcessingStatus.IN_PROGRESS)
        pending_count = repo.count_by_status(ProcessingStatus.PENDING)

        # å‡¦ç†ã‚¿ã‚¤ãƒ—åˆ¥ã®çµ±è¨ˆ
        type_stats: list[dict[str, Any]] = []
        for ptype in ProcessingType:
            completed = repo.count_by_status(ProcessingStatus.COMPLETED, ptype)
            failed = repo.count_by_status(ProcessingStatus.FAILED, ptype)
            total = completed + failed
            success_rate = (completed / total * 100) if total > 0 else 0

            type_stats.append(
                {
                    "å‡¦ç†ã‚¿ã‚¤ãƒ—": ptype.value,
                    "å®Œäº†": completed,
                    "å¤±æ•—": failed,
                    "åˆè¨ˆ": total,
                    "æˆåŠŸç‡": f"{success_rate:.1f}%",
                }
            )

        # éå»7æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        end_date = datetime.now()
        start_date = end_date - timedelta(days=7)
        recent_histories = repo.get_by_date_range(start_date, end_date, limit=1000)

        stats: dict[str, Any] = {
            "completed_count": completed_count,
            "failed_count": failed_count,
            "in_progress_count": in_progress_count,
            "pending_count": pending_count,
            "type_stats": type_stats,
            "recent_histories": recent_histories,
        }

    # å„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ä»¶æ•°ã‚’è¡¨ç¤º
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("âœ… å®Œäº†", stats["completed_count"])

    with col2:
        st.metric("âŒ å¤±æ•—", stats["failed_count"])

    with col3:
        st.metric("â³ å‡¦ç†ä¸­", stats["in_progress_count"])

    with col4:
        st.metric("â¸ï¸ å¾…æ©Ÿä¸­", stats["pending_count"])

    # å‡¦ç†ã‚¿ã‚¤ãƒ—åˆ¥ã®çµ±è¨ˆ
    st.markdown("### å‡¦ç†ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ")

    df = pd.DataFrame(stats["type_stats"])
    st.dataframe(df, use_container_width=True, hide_index=True)  # type: ignore[reportUnknownMemberType]

    # æœ€è¿‘ã®å‡¦ç†å±¥æ­´ã‚°ãƒ©ãƒ•
    st.markdown("### æœ€è¿‘ã®å‡¦ç†å±¥æ­´")

    if stats["recent_histories"]:
        # æ—¥åˆ¥ã®å‡¦ç†ä»¶æ•°ã‚’é›†è¨ˆ
        daily_counts: dict[str, dict[str, int]] = {}
        for history in stats["recent_histories"]:
            if history.created_at:
                date_str = history.created_at.strftime("%Y-%m-%d")
                if date_str not in daily_counts:
                    daily_counts[date_str] = {"completed": 0, "failed": 0}

                if history.status == ProcessingStatus.COMPLETED:
                    daily_counts[date_str]["completed"] += 1
                elif history.status == ProcessingStatus.FAILED:
                    daily_counts[date_str]["failed"] += 1

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
        dates = sorted(daily_counts.keys())
        completed_counts = [daily_counts[date]["completed"] for date in dates]
        failed_counts = [daily_counts[date]["failed"] for date in dates]

        chart_df = pd.DataFrame(
            {
                "æ—¥ä»˜": dates,
                "å®Œäº†": completed_counts,
                "å¤±æ•—": failed_counts,
            }
        )

        st.line_chart(chart_df.set_index("æ—¥ä»˜"))  # type: ignore[reportUnknownMemberType]


def generate_csv_data(histories: list[LLMProcessingHistory]) -> str:
    """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰CSVã‚’ç”Ÿæˆ"""
    output = io.StringIO()
    writer = csv.writer(output)

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    writer.writerow(
        [
            "ID",
            "å‡¦ç†ã‚¿ã‚¤ãƒ—",
            "ãƒ¢ãƒ‡ãƒ«",
            "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
            "å…¥åŠ›å‚ç…§",
            "é–‹å§‹æ™‚åˆ»",
            "å®Œäº†æ™‚åˆ»",
            "å‡¦ç†æ™‚é–“(ç§’)",
            "ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
        ]
    )

    # ãƒ‡ãƒ¼ã‚¿è¡Œ
    for history in histories:
        writer.writerow(
            [
                history.id,
                history.processing_type.value,
                history.model_name,
                history.status.value,
                f"{history.input_reference_type}#{history.input_reference_id}",
                history.started_at.strftime("%Y-%m-%d %H:%M:%S")
                if history.started_at
                else "",
                history.completed_at.strftime("%Y-%m-%d %H:%M:%S")
                if history.completed_at
                else "",
                history.processing_duration_seconds
                if history.processing_duration_seconds
                else "",
                history.error_message if history.error_message else "",
            ]
        )

    return output.getvalue()


def manage_llm_history():
    """LLMå±¥æ­´ç®¡ç†ã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆåŒæœŸç‰ˆï¼‰"""
    render_llm_history_page()
