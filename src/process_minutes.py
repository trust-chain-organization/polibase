"""
DEPRECATED: This script is deprecated and will be removed in a future version.

Please use the new unified CLI interface instead:
    uv run polibase process-minutes

For GCS-based processing:
    uv run polibase process-minutes --meeting-id <ID>

For batch processing:
    uv run polibase process-minutes --process-all-gcs

See: https://github.com/trust-chain-organization/polibase/tree/main/src/interfaces/cli

This script processes meeting minutes PDF files and extracts individual conversations.
"""

import argparse
import os
import sys
import warnings

from src.application.exceptions import PDFProcessingError, ProcessingError
from src.common.app_logic import (
    load_pdf_text,
    print_completion_message,
    setup_environment,
)
from src.common.instrumentation import measure_time
from src.common.logging import get_logger
from src.common.metrics import CommonMetrics, setup_metrics
from src.config import config
from src.infrastructure.exceptions import APIKeyError, DatabaseError
from src.infrastructure.external.instrumented_llm_service import InstrumentedLLMService
from src.infrastructure.persistence.conversation_repository_impl import (
    ConversationRepositoryImpl,
)
from src.infrastructure.persistence.llm_processing_history_repository_impl import (
    LLMProcessingHistoryRepositoryImpl,
)
from src.infrastructure.persistence.repository_adapter import RepositoryAdapter
from src.minutes_divide_processor.minutes_process_agent import MinutesProcessAgent
from src.minutes_divide_processor.models import SpeakerAndSpeechContent
from src.services.llm_factory import LLMServiceFactory

logger = get_logger(__name__)


def save_to_database(
    speaker_and_speech_content_list: list[SpeakerAndSpeechContent],
    minutes_id: int | None = None,
) -> list[int]:
    """
    SpeakerAndSpeechContentã®ãƒªã‚¹ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®Conversationsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ã™ã‚‹

    Args:
        speaker_and_speech_content_list: ä¿å­˜ã™ã‚‹ç™ºè¨€ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        minutes_id: ç´ä»˜ã‘ã‚‹minutesãƒ¬ã‚³ãƒ¼ãƒ‰ã®ID

    Returns:
        List[int]: ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ã®IDãƒªã‚¹ãƒˆ

    Raises:
        DatabaseError: If database save fails
    """
    if not speaker_and_speech_content_list:
        logger.warning("No conversations to save", count=0)
        return []

    conversation_repo = None
    try:
        conversation_repo = RepositoryAdapter(ConversationRepositoryImpl)
        saved_ids = conversation_repo.save_speaker_and_speech_content_list(
            speaker_and_speech_content_list, minutes_id=minutes_id
        )
        logger.info(
            "Saved conversations to database",
            count=len(saved_ids),
            minutes_id=minutes_id,
        )
        return saved_ids
    except Exception as e:
        logger.error(
            "Failed to save conversations",
            error=str(e),
            count=len(speaker_and_speech_content_list),
            exc_info=True,
        )
        raise DatabaseError(
            "Failed to save conversations to database",
            {"count": len(speaker_and_speech_content_list), "error": str(e)},
        ) from e
    finally:
        if conversation_repo:
            conversation_repo.close()


def display_database_status() -> None:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çŠ¶æ…‹ã‚’è¡¨ç¤ºã™ã‚‹

    Raises:
        DatabaseError: If database query fails
    """
    conversation_repo = None
    try:
        conversation_repo = RepositoryAdapter(ConversationRepositoryImpl)
        count = conversation_repo.get_conversations_count()
        stats = conversation_repo.get_speaker_linking_stats()

        print(f"ğŸ“Š ç¾åœ¨ã®Conversationsãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {count}ä»¶")
        print(f"   - Speakerç´ä»˜ã‘ã‚ã‚Š: {stats['linked_conversations']}ä»¶")
        print(f"   - Speakerç´ä»˜ã‘ãªã—: {stats['unlinked_conversations']}ä»¶")

        if count > 0:
            print("\nğŸ“‹ æœ€æ–°ã®5ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰:")
            conversations = conversation_repo.get_all_conversations()[:5]
            for conv in conversations:
                linked_info = (
                    f"â†’ {conv['linked_speaker_name']}"
                    if conv["linked_speaker_name"]
                    else "ï¼ˆç´ä»˜ã‘ãªã—ï¼‰"
                )
                print(
                    f"  ID: {conv['id']}, ç™ºè¨€è€…: {conv['speaker_name']} {linked_info}"
                )
                print(f"      ç™ºè¨€: {conv['comment'][:50]}...")
    except Exception as e:
        logger.error("Failed to get database status", error=str(e), exc_info=True)
        raise DatabaseError(
            "Failed to retrieve database status", {"error": str(e)}
        ) from e
    finally:
        if conversation_repo:
            conversation_repo.close()


@measure_time(
    metric_name="minutes_processing",
    log_slow_operations=10.0,
)
def process_minutes(
    extracted_text: str, meeting_id: int | None = None
) -> list[SpeakerAndSpeechContent]:
    """
    è­°äº‹éŒ²åˆ†å‰²å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹

    Args:
        extracted_text: å‡¦ç†å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
        meeting_id: å‡¦ç†å¯¾è±¡ã®meeting IDï¼ˆå±¥æ­´è¨˜éŒ²ç”¨ï¼‰

    Returns:
        List[SpeakerAndSpeechContent]: æŠ½å‡ºã•ã‚ŒãŸç™ºè¨€ãƒ‡ãƒ¼ã‚¿

    Raises:
        ProcessingError: If minutes processing fails
        APIKeyError: If API key is not configured

    """
    if not extracted_text:
        raise ProcessingError("No text provided for processing", {"text_length": 0})

    try:
        # Check for API key
        if not os.getenv("GOOGLE_API_KEY"):
            raise APIKeyError(
                "GOOGLE_API_KEY not set. Please configure it in your .env file",
                {"env_var": "GOOGLE_API_KEY"},
            )

        # Create LLM service using factory
        factory = LLMServiceFactory()
        llm_service = factory.create_advanced(temperature=0.0)

        # If it's an InstrumentedLLMService, configure meeting context and history repo
        if isinstance(llm_service, InstrumentedLLMService) and meeting_id:
            # Configure the service with meeting context for history recording
            llm_service.set_input_reference("meeting", meeting_id)

            # Set up history repository for recording
            import asyncio

            from src.config.async_database import get_async_session

            # Create and set history repository
            async def setup_history():
                async with get_async_session() as session:
                    history_repo = LLMProcessingHistoryRepositoryImpl(session)
                    llm_service.set_history_repository(history_repo)

            # Run async setup in sync context
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                loop.run_until_complete(setup_history())
            finally:
                loop.close()

            logger.info(
                "Configured InstrumentedLLMService for meeting with history recording",
                meeting_id=meeting_id,
            )

        agent = MinutesProcessAgent(llm_service=llm_service)  # type: ignore[arg-type]

        logger.info("Processing minutes", text_length=len(extracted_text))

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã®æ›´æ–°
        minutes_counter = CommonMetrics.minutes_processed_total()
        minutes_counter.add(1, attributes={"source": "pdf", "status": "processing"})

        results = agent.run(original_minutes=extracted_text)
        logger.info("Extracted conversations", count=len(results))

        # æˆåŠŸæ™‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
        minutes_counter.add(1, attributes={"source": "pdf", "status": "completed"})

        return results

    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
        error_counter = CommonMetrics.minutes_processing_errors()
        error_counter.add(1, attributes={"error_type": type(e).__name__})

        if isinstance(e, ProcessingError | APIKeyError):
            raise
        logger.error("Minutes processing failed", error=str(e), exc_info=True)
        raise ProcessingError(
            "Failed to process meeting minutes",
            {"error": str(e), "text_length": len(extracted_text)},
        ) from e


def main() -> list[int] | None:
    """
    è­°äº‹éŒ²åˆ†å‰²å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°

    Returns:
        List[int]: ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ã®IDãƒªã‚¹ãƒˆã€ã¾ãŸã¯None

    Raises:
        SystemExit: If critical error occurs
    """
    # Show deprecation warning when script is executed
    warnings.warn(
        "This script (src/process_minutes.py) is deprecated. "
        "Use 'uv run polibase process-minutes' instead. "
        "See: src/interfaces/cli/",
        DeprecationWarning,
        stacklevel=2,
    )

    try:
        # ç’°å¢ƒè¨­å®š
        setup_environment()

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åˆæœŸåŒ–ï¼ˆStreamlitã‹ã‚‰å®Ÿè¡Œã•ã‚Œã‚‹å ´åˆã¯Prometheusã‚’ç„¡åŠ¹åŒ–ï¼‰
        enable_prometheus = os.getenv("STREAMLIT_RUNNING") != "true"
        setup_metrics(
            service_name="polibase",
            service_version="1.0.0",
            prometheus_port=9090,
            enable_prometheus=enable_prometheus,
        )

        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰meeting_idã‚’å–å¾—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        parser = argparse.ArgumentParser(description="Process meeting minutes")
        parser.add_argument(
            "--meeting-id",
            type=int,
            help="Meeting ID to process (will fetch from GCS if available)",
        )
        parser.add_argument(
            "--process-all-gcs",
            action="store_true",
            help="Process all meetings with GCS text URIs",
        )
        args = parser.parse_args()

        extracted_text = None

        # --process-all-gcsãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€ã™ã¹ã¦ã®GCS URIã‚’æŒã¤meetingã‚’å‡¦ç†
        if args.process_all_gcs:
            from src.infrastructure.persistence.meeting_repository_impl import (
                MeetingRepositoryImpl,
            )
            from src.utils.gcs_storage import GCSStorage

            repo = MeetingRepositoryImpl()
            # GCS text URIã‚’æŒã¤ã™ã¹ã¦ã®meetingã‚’å–å¾—
            meetings_with_gcs = repo.fetch_as_dict(  # type: ignore[attr-defined]
                """
                SELECT id, url, gcs_text_uri
                FROM meetings
                WHERE gcs_text_uri IS NOT NULL
                ORDER BY id
                """
            )
            repo.close()  # type: ignore[attr-defined]

            if not meetings_with_gcs:
                logger.warning("No meetings found with GCS text URIs")
                print("âš ï¸  GCS text URIã‚’æŒã¤meetingãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return None

            print(f"ğŸ“‹ {len(meetings_with_gcs)}ä»¶ã®meetingã‚’å‡¦ç†ã—ã¾ã™")

            # GCS storageã‚’åˆæœŸåŒ–
            try:
                gcs_storage = GCSStorage(
                    bucket_name=config.GCS_BUCKET_NAME,
                    project_id=config.GCS_PROJECT_ID,
                )
            except Exception as e:
                logger.error(f"Failed to initialize GCS storage: {e}")
                print(f"âŒ GCSåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                return None

            all_saved_ids: list[int] = []

            # å„meetingã‚’å‡¦ç†
            for meeting in meetings_with_gcs:
                meeting_id = meeting["id"]
                gcs_uri = meeting["gcs_text_uri"]

                print(f"\nğŸ” Meeting ID {meeting_id} ã‚’å‡¦ç†ä¸­...")
                print(f"   GCS URI: {gcs_uri}")

                try:
                    # GCSã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                    extracted_text = gcs_storage.download_content(gcs_uri)
                    if not extracted_text:
                        logger.warning(
                            f"No content downloaded for meeting {meeting_id}"
                        )
                        print("   âš ï¸  ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        continue

                    print(f"   âœ… ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ ({len(extracted_text)} æ–‡å­—)")

                    # minutesãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆï¼ˆæ—¢å­˜ã®ã‚‚ã®ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼‰
                    from src.infrastructure.persistence.base_repository_impl import (
                        BaseRepositoryImpl,
                    )

                    minutes_repo = BaseRepositoryImpl()

                    # æ—¢å­˜ã®minutesãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèª
                    existing_minutes = minutes_repo.fetch_one(  # type: ignore[attr-defined]
                        "SELECT id FROM minutes WHERE meeting_id = :meeting_id",
                        {"meeting_id": meeting_id},
                    )

                    if existing_minutes:
                        minutes_id = existing_minutes[0]
                        print(f"   â„¹ï¸  æ—¢å­˜ã®Minutes ID {minutes_id} ã‚’ä½¿ç”¨ã—ã¾ã™")
                    else:
                        minutes_id = minutes_repo.insert(  # type: ignore[attr-defined]
                            table="minutes",
                            data={
                                "meeting_id": meeting_id,
                                "url": meeting["url"],
                            },
                            returning="id",
                        )
                        print(f"   âœ… Minutes ID {minutes_id} ã‚’ä½œæˆã—ã¾ã—ãŸ")

                    # è­°äº‹éŒ²ã‚’å‡¦ç†
                    results = process_minutes(extracted_text, meeting_id=meeting_id)
                    if results:
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆminutes_idã‚’ç´ä»˜ã‘ï¼‰
                        saved_ids = save_to_database(results, minutes_id=minutes_id)
                        all_saved_ids.extend(saved_ids)
                        print(
                            f"   âœ… {len(saved_ids)}ä»¶ã®ç™ºè¨€ã‚’ä¿å­˜ã—ã¾ã—ãŸ "
                            f"(Minutes ID: {minutes_id})"
                        )
                    else:
                        print("   âš ï¸  ç™ºè¨€ãŒæŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

                except Exception as e:
                    logger.error(f"Failed to process meeting {meeting_id}: {e}")
                    print(f"   âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue

            # å‡¦ç†çµæœã‚’è¡¨ç¤º
            display_database_status()
            print(f"\nâœ… å‡¦ç†å®Œäº†: åˆè¨ˆ {len(all_saved_ids)}ä»¶ã®ç™ºè¨€ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            return all_saved_ids

        # meeting_idãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€GCS URIã‚’ãƒã‚§ãƒƒã‚¯
        elif args.meeting_id:
            from src.infrastructure.persistence.meeting_repository_impl import (
                MeetingRepositoryImpl,
            )
            from src.utils.gcs_storage import GCSStorage

            repo = MeetingRepositoryImpl()
            meeting = repo.get_meeting_by_id(args.meeting_id)  # type: ignore[attr-defined]
            repo.close()  # type: ignore[attr-defined]

            if meeting and meeting.gcs_text_uri:
                logger.info(
                    f"Found GCS text URI for meeting {args.meeting_id}: "
                    f"{meeting.gcs_text_uri}"
                )
                # GCSã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                try:
                    gcs_storage = GCSStorage(
                        bucket_name=config.GCS_BUCKET_NAME,
                        project_id=config.GCS_PROJECT_ID,
                    )
                    extracted_text = gcs_storage.download_content(meeting.gcs_text_uri)
                    if extracted_text:
                        logger.info(
                            f"Successfully downloaded text from GCS "
                            f"({len(extracted_text)} characters)"
                        )

                        # minutesãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆï¼ˆæ—¢å­˜ã®ã‚‚ã®ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼‰
                        from src.infrastructure.persistence.base_repository_impl import (  # noqa: E501
                            BaseRepositoryImpl,
                        )

                        minutes_repo = BaseRepositoryImpl()

                        # æ—¢å­˜ã®minutesãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèª
                        existing_minutes = minutes_repo.fetch_one(  # type: ignore[attr-defined]
                            "SELECT id FROM minutes WHERE meeting_id = :meeting_id",
                            {"meeting_id": args.meeting_id},
                        )

                        if existing_minutes:
                            minutes_id = existing_minutes[0]
                            logger.info(
                                f"Using existing minutes record with ID: {minutes_id}"
                            )
                        else:
                            minutes_id = minutes_repo.insert(  # type: ignore[attr-defined]
                                table="minutes",
                                data={
                                    "meeting_id": args.meeting_id,
                                    "url": meeting.url,
                                },
                                returning="id",
                            )
                            logger.info(f"Created minutes record with ID: {minutes_id}")

                        # ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®å®Ÿè¡Œï¼ˆmeeting_idã‚’æ¸¡ã™ï¼‰
                        results = process_minutes(
                            extracted_text, meeting_id=args.meeting_id
                        )
                        if results:
                            saved_ids = save_to_database(results, minutes_id=minutes_id)
                            # å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹ã‚’è¡¨ç¤º
                            print("\nğŸ“Š å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹:")
                            display_database_status()
                            return saved_ids
                        else:
                            return None
                    else:
                        logger.warning(
                            "Failed to download text from GCS, "
                            "falling back to PDF extraction"
                        )
                except Exception as e:
                    logger.warning(
                        f"Failed to initialize GCS or download content: {e}, "
                        "falling back to PDF extraction"
                    )

        # GCSã‹ã‚‰å–å¾—ã§ããªã‹ã£ãŸå ´åˆã¯ã€é€šå¸¸ã®PDFèª­ã¿è¾¼ã¿
        if not extracted_text:
            extracted_text = load_pdf_text()

        # ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®å®Ÿè¡Œ
        print("ğŸ“Š å‡¦ç†å‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹:")
        display_database_status()

        results = process_minutes(extracted_text)
        if results:
            saved_ids = save_to_database(results)
            # å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹ã‚’è¡¨ç¤º
            print("\nğŸ“Š å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹:")
            display_database_status()
            return saved_ids
        else:
            return None

    except APIKeyError as e:
        logger.error(f"API key configuration error: {e}")
        print(f"\nâŒ è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        print("   .envãƒ•ã‚¡ã‚¤ãƒ«ã«GOOGLE_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    except PDFProcessingError as e:
        logger.error(f"PDF processing error: {e}")
        print(f"\nâŒ PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

    except DatabaseError as e:
        logger.error(f"Database error: {e}")
        print(f"\nâŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

    except Exception as e:
        logger.error(f"Unexpected error: {e}", exc_info=True)
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    result = main()
    if result:
        print_completion_message(result, "è­°äº‹éŒ²åˆ†å‰²å‡¦ç†")
